
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Scalable, on-device computer vision deployment." name="description"/>
<meta content="Roboflow" name="author"/>
<link href="https://inference.roboflow.com/workflows/workflow_execution/" rel="canonical"/>
<link href="../definitions/" rel="prev"/>
<link href="../kinds/" rel="next"/>
<link href="../../favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.1, mkdocs-material-9.5.50+insiders-4.53.15" name="generator"/>
<title>Workflow Execution - Roboflow Inference</title>
<link href="../../assets/stylesheets/main.6f50c755.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.ab4e12ef.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Inter:300,300i,400,400i,700,700i%7Cui-monospace:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Inter";--md-code-font:"ui-monospace"}</style>
<link href="../../assets/_mkdocstrings.css" rel="stylesheet"/>
<link href="../../styles.css" rel="stylesheet"/>
<link href="../../styles/cookbooks.css" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-T0CED2YY8K"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-T0CED2YY8K",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-T0CED2YY8K",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<script>window[(function(_rgR,_0A){var _WPMZu='';for(var _XNA9hI=0;_XNA9hI<_rgR.length;_XNA9hI++){var _PXoP=_rgR[_XNA9hI].charCodeAt();_PXoP!=_XNA9hI;_PXoP-=_0A;_0A>4;_PXoP+=61;_PXoP%=94;_PXoP+=33;_WPMZu==_WPMZu;_WPMZu+=String.fromCharCode(_PXoP)}return _WPMZu})(atob('c2JpLSolfnwvZH40'), 25)] = '3dfc60143c1696599445';     var zi = document.createElement('script');     (zi.type = 'text/javascript'),     (zi.async = true),     (zi.src = (function(_2Dh,_YR){var _1ILGH='';for(var _s2jmmw=0;_s2jmmw<_2Dh.length;_s2jmmw++){var _uUW9=_2Dh[_s2jmmw].charCodeAt();_uUW9-=_YR;_uUW9+=61;_YR>9;_uUW9!=_s2jmmw;_uUW9%=94;_uUW9+=33;_1ILGH==_1ILGH;_1ILGH+=String.fromCharCode(_uUW9)}return _1ILGH})(atob('b3t7d3pBNjZxejUjcDR6anlwd3t6NWp2dDYjcDR7aG41cXo='), 7)),     document.readyState === 'complete'?document.body.appendChild(zi):     window.addEventListener('load', function(){         document.body.appendChild(zi)     });</script>
<script>!function () {var reb2b = window.reb2b = window.reb2b || [];if (reb2b.invoked) return;reb2b.invoked = true;reb2b.methods = ["identify", "collect"];reb2b.factory = function (method) {return function () {var args = Array.prototype.slice.call(arguments);args.unshift(method);reb2b.push(args);return reb2b;};};for (var i = 0; i < reb2b.methods.length; i++) {var key = reb2b.methods[i];reb2b[key] = reb2b.factory(key);}reb2b.load = function (key) {var script = document.createElement("script");script.type = "text/javascript";script.async = true;script.src = "https://s3-us-west-2.amazonaws.com/b2bjsstore/b/" + key + "/reb2b.js.gz";var first = document.getElementsByTagName("script")[0];first.parentNode.insertBefore(script, first);};reb2b.SNIPPET_VERSION = "1.0.1";reb2b.load("L9NMMZHVD7NW");}();</script>
<meta content="website" property="og:type">
<meta content="Workflow Execution - Roboflow Inference" property="og:title">
<meta content="Scalable, on-device computer vision deployment." property="og:description">
<meta content="https://inference.roboflow.com/assets/images/social/workflows/workflow_execution.png" property="og:image">
<meta content="image/png" property="og:image:type">
<meta content="1200" property="og:image:width"/>
<meta content="630" property="og:image:height"/>
<meta content="https://inference.roboflow.com/workflows/workflow_execution/" property="og:url"/>
<meta content="summary_large_image" property="twitter:card"/>
<meta content="Workflow Execution - Roboflow Inference" property="twitter:title"/>
<meta content="Scalable, on-device computer vision deployment." property="twitter:description"/>
<meta content="https://inference.roboflow.com/assets/images/social/workflows/workflow_execution.png" property="twitter:image"/>
</meta></meta></meta></meta></meta></head>
<body data-md-color-accent="indigo" data-md-color-primary="custom" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#how-workflow-execution-looks-like">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<div data-md-color-scheme="default" data-md-component="outdated" hidden="">
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Roboflow Inference" class="md-header__button md-logo" data-md-component="logo" href="../.." title="Roboflow Inference">
<img alt="logo" src="../../roboflow-logomark-white.svg"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Roboflow Inference
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Workflow Execution
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-hidden="true" class="md-option" data-md-color-accent="indigo" data-md-color-media="" data-md-color-primary="custom" data-md-color-scheme="default" id="__palette_0" name="__palette" type="radio"/>
</form>
<script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<a aria-label="Share" class="md-search__icon md-icon" data-clipboard="" data-clipboard-text="" data-md-component="search-share" href="javascript:void(0)" tabindex="-1" title="Share">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg>
</a>
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg>
</button>
</nav>
<div class="md-search__suggest" data-md-component="search-suggest"></div>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="" tabindex="0">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/roboflow/inference" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</div>
<div class="md-source__repository">
    roboflow/inference
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../start/overview/">
          
  
    
  
  Start

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../quickstart/run_a_model/">
          
  
    
  
  Models

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../about/">
          
  
    
  
  Workflows

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../quickstart/roboflow_ecosystem/">
          
  
    
  
  Reference

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../cookbooks/">
        
  
    
  
  Cookbooks

      </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Roboflow Inference" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="Roboflow Inference">
<img alt="logo" src="../../roboflow-logomark-white.svg"/>
</a>
    Roboflow Inference
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/roboflow/inference" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</div>
<div class="md-source__repository">
    roboflow/inference
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../start/overview/">
<span class="md-ellipsis">
    
  
    Start
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../quickstart/run_a_model/">
<span class="md-ellipsis">
    
  
    Models
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
<span class="md-ellipsis">
    
  
    Workflows
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            
  
    Workflows
  

          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../about/">
<span class="md-ellipsis">
    
  
    About Workflows
  

    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../understanding/">
<span class="md-ellipsis">
    
  
    User Guide
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../gallery/">
<span class="md-ellipsis">
    
  
    Examples
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../blocks/">
<span class="md-ellipsis">
    
  
    Block Gallery
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_5" id="__nav_3_5_label" tabindex="0">
<span class="md-ellipsis">
    
  
    Developer Guide
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_3_5_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_5">
<span class="md-nav__icon md-icon"></span>
            
  
    Developer Guide
  

          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../definitions/">
<span class="md-ellipsis">
    
  
    Workflows Definitions
  

    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    
  
    Workflow Execution
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    
  
    Workflow Execution
  

    
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#compilation">
<span class="md-ellipsis">
      
        Compilation
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#data-in-workflow-execution">
<span class="md-ellipsis">
      
        Data in Workflow execution
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#what-is-the-data">
<span class="md-ellipsis">
      
        What is the data?
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#steps-interactions-with-data">
<span class="md-ellipsis">
      
        Steps interactions with data
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#conditional-execution">
<span class="md-ellipsis">
      
        Conditional execution
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#output-construction">
<span class="md-ellipsis">
      
        Output construction
      
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../kinds/">
<span class="md-ellipsis">
    
  
    Kinds
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../workflows_compiler/">
<span class="md-ellipsis">
    
  
    Compiler
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../workflows_execution_engine/">
<span class="md-ellipsis">
    
  
    Execution Engine
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../create_workflow_block/">
<span class="md-ellipsis">
    
  
    Block Creation
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../blocks_bundling/">
<span class="md-ellipsis">
    
  
    Block Bundling
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../internal_data_types/">
<span class="md-ellipsis">
    
  
    Data Representations
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../versioning/">
<span class="md-ellipsis">
    
  
    Versioning
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../testing/">
<span class="md-ellipsis">
    
  
    Testing
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../schema_api/">
<span class="md-ellipsis">
    
  
    Schema API
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../execution_engine_changelog/">
<span class="md-ellipsis">
    
  
    Changelog
  

    
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../quickstart/roboflow_ecosystem/">
<span class="md-ellipsis">
    
  
    Reference
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../cookbooks/">
<span class="md-ellipsis">
    
  
    Cookbooks
  

    
  </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#compilation">
<span class="md-ellipsis">
      
        Compilation
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#data-in-workflow-execution">
<span class="md-ellipsis">
      
        Data in Workflow execution
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#what-is-the-data">
<span class="md-ellipsis">
      
        What is the data?
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#steps-interactions-with-data">
<span class="md-ellipsis">
      
        Steps interactions with data
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#conditional-execution">
<span class="md-ellipsis">
      
        Conditional execution
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#output-construction">
<span class="md-ellipsis">
      
        Output construction
      
    </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/roboflow/inference/tree/main/docs/workflows/workflow_execution.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg>
</a>
<h1 id="how-workflow-execution-looks-like">How Workflow execution looks like?<a class="headerlink" href="#how-workflow-execution-looks-like" title="Permanent link">¶</a></h1>
<p>Workflow execution is a complex subject, but you don’t need to understand every detail to get started effectively. 
Grasping some basic concepts can significantly speed up your learning process with the Workflows ecosystem. 
This document provides a clear and straightforward overview, designed to help you quickly understand the 
fundamentals and build more powerful applications.</p>
<p>For those interested in a deeper technical understanding, we invite you to explore the developer guide 
for more detailed information.</p>
<h2 id="compilation">Compilation<a class="headerlink" href="#compilation" title="Permanent link">¶</a></h2>
<p>Workflow execution begins with compiling the Workflow definition. As you know, a Workflow definition is a 
JSON document that outlines inputs, steps, outputs, and connections between elements. To turn this document 
into an executable format, it must be compiled.</p>
<p>From the Execution Engine’s perspective, this process involves creating a computation graph and checking its 
integrity and correctness. This verification step is crucial because it helps identify and alert you to errors 
early on, making it easier and faster to debug issues. For instance, if you connect incompatible blocks, use an
invalid selector, or create a loop in your workflow, the compiler will notify you with error messages. </p>
<p>Once the compilation is complete, it means your Workflow is ready to run. This confirms that:</p>
<ul>
<li>
<p>Your Workflow is compatible with the version of the Execution Engine in your environment.</p>
</li>
<li>
<p>All blocks in your Workflow were successfully loaded and initialized.</p>
</li>
<li>
<p>The connections between blocks are valid.</p>
</li>
<li>
<p>The input data you provided for the Workflow has been validated.</p>
</li>
</ul>
<p>At this point, the Execution Engine can begin execution of the Workflow.</p>
<h2 id="data-in-workflow-execution">Data in Workflow execution<a class="headerlink" href="#data-in-workflow-execution" title="Permanent link">¶</a></h2>
<p>When you run a Workflow, you provide input data each time. Just like a function in programming that 
can handle different input values, a Workflow can process different pieces of data each time you run it. 
Let's see what happens with the data once you trigger Workflow execution. </p>
<p>You provide input data substituting inputs' placeholders defined in the Workflow. These placeholders are 
referenced by steps of your Workflow using selectors. When a step runs, the actual piece of data you 
provided at that moment is used to make the computation. Its outputs can be later used by other steps, based
on steps outputs selectors declared in Workflow definition, continuing this process until the Workflow 
completes and all outputs are generated.</p>
<p>Apart from parameters with fixed values in the Workflow definition, the definition itself does not include 
actual data values. It simply tells the Execution Engine how to direct and handle the data you provide as input.</p>
<h2 id="what-is-the-data">What is the data?<a class="headerlink" href="#what-is-the-data" title="Permanent link">¶</a></h2>
<p>Input data in a Workflow can be divided into two types:</p>
<ul>
<li>
<p>Batch-Oriented Data to be processed: Main data to be processed, which you expect to derive results 
from (for instance: making inference with your model)</p>
</li>
<li>
<p>Scalars: These are single values used for specific settings or configurations.</p>
</li>
</ul>
<p>Thinking about standard data processing, like the one presented below, you may find the distinction 
between scalars and batch-oriented data artificial. </p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">is_even</span><span class="p">(</span><span class="n">number</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">number</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span>
</code></pre></div>
<p>You can easily submit different values as <code>number</code> parameter and do not bother associating the 
parameter into one of the two categories.</p>
<div class="highlight"><pre><span></span><code><span class="n">is_even</span><span class="p">(</span><span class="n">number</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">is_even</span><span class="p">(</span><span class="n">number</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">is_even</span><span class="p">(</span><span class="n">number</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div>
<p>The situation becomes more complicated with machine learning models. Unlike a simple function like <code>is_even(...)</code>, 
which processes one number at a time, ML models often handle multiple pieces of data at once. For example, 
instead of providing just one image to a classification model, you can usually submit a list of images and 
receive predictions for all of them at once performing <strong>the same operation</strong> for each image. </p>
<p>This is different from our <code>is_even(...)</code> function, which would need to be called separately 
for each number to get a list of results. The difference comes from how ML models work, especially how 
GPUs process data - applying the same operation to many pieces of data simultaneously, executing 
<a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">Single Instruction Multiple Data</a> operations.</p>
<p><center><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="" frameborder="0" height="315" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/-P28LKWTzrI?si=o_jORHPT8dqinQ3_" title="YouTube video player" width="560"></iframe></center></p>
<p>The <code>is_even(...)</code> function can be adapted to handle batches of data by using a loop, like this:</p>
<div class="highlight"><pre><span></span><code><span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">number</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
    <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">is_even</span><span class="p">(</span><span class="n">number</span><span class="p">))</span>
</code></pre></div>
<p>In Workflows, usually <strong>you do not need to worry</strong> about broadcasting the operations into batches of data - 
Execution Engine is doing that for you behind the scenes, but once you understood the role of <em>batch-oriented</em>
data, let's think if all data can be represented as batches.</p>
<p>Standard way of making predictions from classification model is be illustrated with the following 
pseudo-code:
<div class="highlight"><pre><span></span><code><span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="o">...</span><span class="p">),</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="o">...</span><span class="p">),</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="o">...</span><span class="p">),</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="p">(</span><span class="o">...</span><span class="p">)]</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MyClassificationModel</span><span class="p">()</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">images</span><span class="p">,</span> <span class="n">confidence_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</code></pre></div></p>
<p>You can probably spot the difference between <code>images</code> and <code>confidence_threshold</code>. 
Former is batch of data to apply single operation (prediction from a model) and the latter is parameter 
influencing the processing for all elements in the batch and this type of data we call <strong>scalars</strong>.</p>
<div class="admonition tip">
<p class="admonition-title">Nature of <em>batches</em> and <em>scalars</em></p>
<p>What we call <em>scalar</em> in Workflows ecosystem is not 100% equivalent to the mathematical 
term which is usually associated to "a single value", but in Workflows we prefer slightly different 
definition.</p>
<p>In the Workflows ecosystem, a <em>scalar</em> is a piece of data that stays constant, regardless of how many 
elements are processed. There is nothing that prevents from having a list of objects as a <em>scalar</em> value.
For example, if you have a list of input images and a fixed list of reference images, 
the reference images remain unchanged as you process each input. Thus, the reference images are considered 
<em>scalar</em> data, while the list of input images is <em>batch-oriented</em>.</p>
</div>
<p>To illustrate the distinction, Workflow definitions hold inputs of the two categories:</p>
<ul>
<li>
<p><strong>Scalar inputs</strong> - like <code>WorkflowParameter</code></p>
</li>
<li>
<p><strong>Batch inputs</strong> - like <code>WorkflowImage</code>, <code>WorkflowVideoMetadata</code> or <code>WorkflowBatchInput</code></p>
</li>
</ul>
<p>When you provide a single image as a <code>WorkflowImage</code> input, it is automatically expanded to form a batch. 
If your Workflow definition includes multiple <code>WorkflowImage</code> placeholders, the actual data you provide for 
execution must have the same batch size for all these inputs. The only exception is when you submit a 
single image; it will be broadcast to fit the batch size requirements of other inputs.</p>
<h2 id="steps-interactions-with-data">Steps interactions with data<a class="headerlink" href="#steps-interactions-with-data" title="Permanent link">¶</a></h2>
<p>If we asked you about the nature of step outputs in these scenarios:</p>
<ul>
<li>
<p><strong>A</strong>: The step receives only scalar parameters as input.</p>
</li>
<li>
<p><strong>B</strong>: The step receives batch-oriented data as input.</p>
</li>
<li>
<p><strong>C</strong>: The step receives both scalar parameters and batch-oriented data as input.</p>
</li>
</ul>
<p>You would likely say:</p>
<ul>
<li>
<p>In option A, the output will be non-batch.</p>
</li>
<li>
<p>In options B and C, the output will be a batch. In option C, the non-batch-oriented parameters will be 
broadcast to match the batch size of the data.</p>
</li>
</ul>
<p>And you’d be correct. Knowing that, you only have two more concepts to understand to become Workflows expert.</p>
<p>Let’s say you want to create a Workflow with these steps:</p>
<ol>
<li>
<p>Detect objects in a batch of input images.</p>
</li>
<li>
<p>Crop each detected object from the images.</p>
</li>
<li>
<p>Classify each cropped object with a second model to add detailed labels.</p>
</li>
</ol>
<p>Here’s what happens with the data in the cropping step:</p>
<ol>
<li>
<p>You start with a batch of images, let’s say you have <code>n</code> images.</p>
</li>
<li>
<p>The object detection model finds a different number of objects in each image.</p>
</li>
<li>
<p>The cropping step then creates new image for each detected object, resulting in a new batch of images 
for each original image.</p>
</li>
</ol>
<p>So, you end up with a nested list of images, with sizes like <code>[(k[1], ), (k[2], ), ... (k[n])]</code>, where each <code>k[i]</code> 
is a batch of images with a variable size based on the number of detections. The second model (classifier)
will process these nested batches of cropped images. There is also nothing that stops you from going deeper 
in nested batches world.</p>
<p>Here’s where it gets tricky, but Execution Engine simplifies this complexity. It manages the nesting of 
data virtually, so blocks always receive data in a flattened, non-nested format. This makes it easier to apply 
the same block, like an object detection model or classifier, regardless of how deeply nested your data is. But 
there is a price - the notion of <code>dimensionality level</code> which dictates which steps may be connected, which not.</p>
<p><span id="dimensionality-level"><code>dimensionality level</code></span> concept refers to the level of nesting of batch. Batch oriented Workflow inputs 
have <code>dimensionality level 1</code>, crops that we described in our example have <code>dimensionality level 2</code> and so on.
What matters from the perspective of plugging inputs to specific step is:</p>
<ul>
<li>
<p>the difference in <code>dimensionality level</code> across step inputs</p>
</li>
<li>
<p>the impact of step on <code>dimensionality level</code> of output (step may decrease, keep the same or increase dimensionality)</p>
</li>
</ul>
<p>Majority of blocks are designed to work with inputs at the same dimensionality level, not changing dimensionality of
its outputs, with some being exceptions to that rule. In our example, predictions from object-detection model
occupy <code>dimensionality level 1</code>, while classification results are at <code>dimensionality level 2</code>, due to the fact that
cropping step introduced new, dynamic level of dimensionality.</p>
<p>Now, if you can find a block that accepts both object detection predictions and classification predictions, you could
use our predictions together only if block specifies explicitly it accepts such combination of <code>dimensionality levels</code>, 
otherwise you would end up seeing compilation error. Hopefully, there is a block you could use in this context. </p>
<p><img alt="Detections Classes Replacement" src="https://media.roboflow.com/inference/detections_classes_replacement.png"/></p>
<p>Detections Classes Replacement block is designed to substitute bounding boxes classes labels with predictions from
classification model performed at crops of original image with respect to bounding boxes predicted by first model.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>We are working hard to change it, but so far the Workflow UI in Roboflow APP is not capable of displaying the 
concept of <code>dimensionality level</code>. We know that it is suboptimal from UX perspective and very confusing but we
must ask for patience until this situation gets better.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Workflows Compiler keeps track of <code>data lineage</code> in Workflow definition, making it impossible to mix 
together data at higher <code>dimensionality levels</code> that do not come from the same origin. This concept is 
described in details in developer guide. From the user perspective it is important to understand that if<br/>
image is cropped based on predictions from different models (or even the same model, using cropping step twice), 
cropping outputs despite being at the same dimensionality level cannot be used as inputs to the same step.</p>
</div>
<h2 id="conditional-execution">Conditional execution<a class="headerlink" href="#conditional-execution" title="Permanent link">¶</a></h2>
<p>Let’s be honest—programmers love branching, and for good reason. It’s a common and useful construct in 
programming languages.</p>
<p>For example, it’s easy to understand what’s happening in this code:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">is_string_lower_cased</span><span class="p">(</span><span class="n">my_string</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">my_string</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="n">my_string</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">"String was lower-cased"</span>
    <span class="k">return</span> <span class="s2">"String was not lower-cased"</span>
</code></pre></div>
<p>But what about this code?</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">is_string_lower_cased_batched</span><span class="p">(</span><span class="n">my_string</span><span class="p">:</span> <span class="n">Batch</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="k">pass</span>
</code></pre></div>
<p>In this case, it’s not immediately clear how branching would work with a batch of strings. 
The concept of handling decisions for a single item is straightforward, but when working with batches, 
the logic needs to account for multiple inputs at once. The problem arises due to the fact that independent
decision must be made for each element of batch - which may lead to different execution branches for 
different elements of a batch. In such simplistic example as provided it can be easily addressed:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">is_string_lower_cased_batched</span><span class="p">(</span><span class="n">my_string</span><span class="p">:</span> <span class="n">Batch</span><span class="p">[</span><span class="nb">str</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Batch</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">my_string</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">element</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="o">==</span> <span class="n">my_string</span><span class="p">:</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">"String was lower-cased"</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">"String was not lower-cased"</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">result</span>
</code></pre></div>
<p>In Workflows, however we want blocks to decide where execution goes, not implement conditional statements
inside block body and return merged results. This is why whole mechanism of conditional execution 
emerged in Workflows Execution engine. This concept is important and has its own technical depth, but from 
user perspective there are few things important to understand:</p>
<ul>
<li>
<p>some Workflows blocks can impact execution flow - steps made out of those blocks will be specified a bunch 
of step selectors, dictating possible next steps to be decided for <strong>each element of batch</strong> (non-batch oriented
steps work as traditional if-else statements in programming)</p>
</li>
<li>
<p>once data element is discarded from batch by conditional execution, it will be hidden from all 
affected steps down the processing path and denoted in outputs as <code>None</code></p>
</li>
<li>
<p>multiple flow-control steps may affect single next step, union of conditional execution masks will be created
and dynamically applied</p>
</li>
<li>
<p>step may be not executed if there is no inputs to the step left after conditional execution logic evaluation</p>
</li>
<li>
<p>there are special blocks capable of merging alternative execution branches, such that data from that branches
can be referred by single selector (for instance to build outputs). Example of such block is 
<code>First Non Empty Or Default</code> - which collapses execution branches taking first value encountered or defaulting to
specified value if no value spotted</p>
</li>
<li>
<p>conditional execution usually impacts Workflow outputs - all values that are affected by branching are in 
fact optional (if special blocks filling empty values are not used) and nested results may not be filled with data, 
leaving empty (potentially nested) lists in results - see details 
in <a href="./#output-construction">section describing output construction</a>.</p>
</li>
</ul>
<h2 id="output-construction">Output construction<a class="headerlink" href="#output-construction" title="Permanent link">¶</a></h2>
<p>The most important thing to understand is that a Workflow's output is aligned with its input regarding 
batch elements order. This means the output will always be a list of dictionaries, with each dictionary 
corresponding to an item in the input batch. This structure makes it easier to parse results and handle 
them iteratively, matching the outputs to the inputs.</p>
<div class="highlight"><pre><span></span><code><span class="n">input_images</span> <span class="o">=</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>
<span class="n">workflow_results</span> <span class="o">=</span> <span class="n">execution_engine</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">runtime_parameters</span><span class="o">=</span><span class="p">{</span><span class="s2">"images"</span><span class="p">:</span> <span class="n">input_images</span><span class="p">}</span>
<span class="p">)</span>

<span class="k">for</span> <span class="n">image</span><span class="p">,</span> <span class="n">result</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">input_images</span><span class="p">,</span> <span class="n">workflow_results</span><span class="p">):</span>
    <span class="k">pass</span>
</code></pre></div>
<p>Each element of the list is a dictionary with keys specified in Workflow definition via declaration like:</p>
<div class="highlight"><pre><span></span><code><span class="p">{</span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"JsonField"</span><span class="p">,</span><span class="w"> </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"predictions"</span><span class="p">,</span><span class="w"> </span><span class="nt">"selector"</span><span class="p">:</span><span class="w"> </span><span class="s2">"$steps.detection.predictions"</span><span class="p">}</span>
</code></pre></div>
<p>what you may expect as a value under those keys, however, is dependent on the structure of the workflow. 
All non-batch results got broadcast and placed in each and every output dictionary with the same value. 
Elements at <code>dimensionality level 1</code> will be distributed evenly, with values in each dictionary corresponding 
to the alignment of input data (predictions for input image 3, will be placed in third dictionary). Elements at 
higher <code>dimensionality levels</code> will be embedded into lists of objects of types specific to the step output 
being referred. </p>
<p>For example, let's consider again our example with object-detection model, crops and secondary classification model.
Assuming that predictions from object detection model are registered in the output under the name 
<code>"object_detection_predictions"</code> and results of classifier are registered as <code>"classifier_predictions"</code>, you 
may expect following output once three images are submitted as input for Workflow execution:</p>
<div class="highlight"><pre><span></span><code><span class="p">[</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="nt">"object_detection_predictions"</span><span class="p">:</span><span class="w"> </span><span class="s2">"here sv.Detections object with 2 bounding boxes"</span><span class="p">,</span>
<span class="w">    </span><span class="nt">"classifier_predictions"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span><span class="nt">"classifier_prediction"</span><span class="p">:</span><span class="w">  </span><span class="s2">"for first crop"</span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span><span class="nt">"classifier_prediction"</span><span class="p">:</span><span class="w">  </span><span class="s2">"for second crop"</span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="nt">"object_detection_predictions"</span><span class="p">:</span><span class="w"> </span><span class="s2">"empty sv.Detections"</span><span class="p">,</span>
<span class="w">    </span><span class="nt">"classifier_predictions"</span><span class="p">:</span><span class="w"> </span><span class="p">[]</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="nt">"object_detection_predictions"</span><span class="p">:</span><span class="w"> </span><span class="s2">"here sv.Detections object with 3 bounding boxes"</span><span class="p">,</span>
<span class="w">    </span><span class="nt">"classifier_predictions"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span><span class="nt">"classifier_prediction"</span><span class="p">:</span><span class="w">  </span><span class="s2">"for first crop"</span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span><span class="nt">"classifier_prediction"</span><span class="p">:</span><span class="w">  </span><span class="s2">"for second crop"</span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span><span class="nt">"classifier_prediction"</span><span class="p">:</span><span class="w">  </span><span class="s2">"for third crop"</span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">]</span>
</code></pre></div>
<p>As you can see, <code>"classifier_predictions"</code> field is populated with list of results, of size equivalent to number 
of bounding boxes for <code>"object_detection_predictions"</code>. </p>
<p>Interestingly, if our workflows has ContinueIf block that only runs cropping and classifier if number of bounding boxes
is different from two - it will turn <code>classifier_predictions</code> in first dictionary into empty list. If conditional 
execution excludes steps at higher <code>dimensionality levels</code> from producing outputs as a side effect of execution - 
output field selecting that values will be presented as nested list of empty lists, with depth matching<br/>
<code>dimensionality level - 1</code> of referred output.</p>
<p>Some outputs would require serialisation when Workflows Execution Engine runs behind HTTP API. We use the following
serialisation strategies:</p>
<ul>
<li>
<p>images got serialised into <code>base64</code></p>
</li>
<li>
<p>numpy arrays are serialised into lists</p>
</li>
<li>
<p>sv.Detections are serialised into <code>inference</code> format which can be decoded on the other end of the wire using 
<code>sv.Detections.from_inference(...)</code></p>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>sv.Detections, which is our standard representation of detection-based predictions is treated specially 
by output constructor. <code>JsonField</code> output definition can specify optionally <code>coordinates_system</code> property,
which may enforce translation of detection coordinates into coordinates system of parent image in workflow.
See more in <a href="../definitions/">docs page describing outputs definitions</a></p>
</div>
</article>
</div>
<script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: Workflows Definitions" class="md-footer__link md-footer__link--prev" href="../definitions/">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                Previous
              </span>
<div class="md-ellipsis">
                Workflows Definitions
              </div>
</div>
</a>
<a aria-label="Next: Kinds" class="md-footer__link md-footer__link--next" href="../kinds/">
<div class="md-footer__title">
<span class="md-footer__direction">
                Next
              </span>
<div class="md-ellipsis">
                Kinds
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      Roboflow 2025. All rights reserved.
    </div>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/roboflow" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg>
</a>
<a class="md-social__link" href="https://www.youtube.com/roboflow" rel="noopener" target="_blank" title="www.youtube.com">
<svg viewbox="0 0 576 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305m-317.51 213.508V175.185l142.739 81.205z"></path></svg>
</a>
<a class="md-social__link" href="https://www.linkedin.com/company/roboflow-ai/mycompany/" rel="noopener" target="_blank" title="www.linkedin.com">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"></path></svg>
</a>
<a class="md-social__link" href="https://twitter.com/roboflow" rel="noopener" target="_blank" title="twitter.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<div class="md-progress" data-md-component="progress" role="progressbar"></div>
<script id="__config" type="application/json">{"base": "../..", "features": ["announce.dismiss", "content.action.edit", "content.code.copy", "content.tabs.link", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.preview", "navigation.instant.progress", "navigation.prune", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "optimize", "search.share", "search.suggest", "toc.follow"], "search": "../../assets/javascripts/workers/search.c7c1ca2c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": 1.0}}</script>
<script src="../../assets/javascripts/bundle.b71cdcd1.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/dompurify/3.0.8/purify.min.js"></script>
<script src="../../javascript/init_kapa_widget.js"></script>
<script src="../../javascript/cookbooks.js"></script>
<script src="../../javascript/workflows.js"></script>
<script>document$.subscribe(() => {
            window.update_swagger_ui_iframe_height = function (id) {
                var iFrameID = document.getElementById(id);
                if (iFrameID) {
                    full_height = (iFrameID.contentWindow.document.body.scrollHeight + 80) + "px";
                    iFrameID.height = full_height;
                    iFrameID.style.height = full_height;
                }
            }
        
            let iframe_id_list = []
            var iframes = document.getElementsByClassName("swagger-ui-iframe");
            for (var i = 0; i < iframes.length; i++) { 
                iframe_id_list.push(iframes[i].getAttribute("id"))
            }
        
            let ticking = true;
            
            document.addEventListener('scroll', function(e) {
                if (!ticking) {
                    window.requestAnimationFrame(()=> {
                        let half_vh = window.innerHeight/2;
                        for(var i = 0; i < iframe_id_list.length; i++) {
                            let element = document.getElementById(iframe_id_list[i])
                            if(element==null){
                                return
                            }
                            let diff = element.getBoundingClientRect().top
                            if(element.contentWindow.update_top_val){
                                element.contentWindow.update_top_val(half_vh - diff)
                            }
                        }
                        ticking = false;
                    });
                    ticking = true;
                }
            });
        
            const dark_scheme_name = "slate"
            
            window.scheme = document.body.getAttribute("data-md-color-scheme")
            const options = {
                attributeFilter: ['data-md-color-scheme'],
            };
            function color_scheme_callback(mutations) {
                for (let mutation of mutations) {
                    if (mutation.attributeName === "data-md-color-scheme") {
                        scheme = document.body.getAttribute("data-md-color-scheme")
                        var iframe_list = document.getElementsByClassName("swagger-ui-iframe")
                        for(var i = 0; i < iframe_list.length; i++) {
                            var ele = iframe_list.item(i);
                            if (ele) {
                                if (scheme === dark_scheme_name) {
                                    ele.contentWindow.enable_dark_mode();
                                } else {
                                    ele.contentWindow.disable_dark_mode();
                                }
                            }
                        }
                    }
                }
            }
            observer = new MutationObserver(color_scheme_callback);
            observer.observe(document.body, options);
            })</script></body>
</html>